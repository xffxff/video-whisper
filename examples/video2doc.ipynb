{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e32fd3-be21-4dc5-8715-8a239e3b1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87019493-e101-482e-a428-0df5293ca773",
   "metadata": {},
   "source": [
    "## Split The Video\n",
    "\n",
    "Split the video into seperate clips using [`PySceneDetect`](https://www.scenedetect.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc13ff6d-a0ec-4548-a567-55f43ee3b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = 'How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg].mkv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6012e66-ab9f-40d7-879e-5e838509ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scenedetect -i \"$video_file\" split-video -o video_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7d08a2-3cc4-4bcf-b7f7-b09930aa6af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from video2doc.video_understanding import VideoUnderstandingWithAriaHQQInt4, load_video, fix_json, timestamp_to_seconds, get_frame_at_timestamp, split_video_into_scenes\n",
    "from video2doc.whisper import Whisper, extract_audio, merge_chunks_by_timerange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339c81c2-eeef-40be-908b-8fa1b157516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████| 12/12 [00:02<00:00,  4.12it/s]\n",
      "100%|████████████████████████████████████████████████| 28/28 [05:08<00:00, 11.01s/it]\n",
      "100%|█████████████████████████████████████████████| 199/199 [00:00<00:00, 697.48it/s]\n",
      "100%|██████████████████████████████████████████████| 197/197 [00:12<00:00, 15.19it/s]\n",
      "100%|█████████████████████████████████████████████| 197/197 [00:00<00:00, 535.32it/s]\n",
      "  0%|                                                          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████                                        | 1/5 [00:39<02:36, 39.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████                              | 2/5 [00:40<00:51, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████                    | 3/5 [00:43<00:20, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████          | 4/5 [00:44<00:06,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 5/5 [00:46<00:00,  9.29s/it]\n"
     ]
    }
   ],
   "source": [
    "whisper = Whisper(device='cuda:0')\n",
    "video_understanding_with_aria = VideoUnderstandingWithAriaHQQInt4('rhymes-ai/Aria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03a64dd-d53b-4afd-8e5b-fc47693fe50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def process_video_to_doc(video_file: str, video_name: str, output_folder: str):\n",
    "    \"\"\"Process a video file and save scenes with transcriptions to markdown\"\"\"\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_folder)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    audio_path = extract_audio(video_file)\n",
    "    transcription = whisper(audio_path)\n",
    "    \n",
    "    frames, timestemps = load_video(video_file)\n",
    "    scenes = split_video_into_scenes(video_understanding_with_aria, frames, timestemps)\n",
    "    \n",
    "    # Create markdown content\n",
    "    markdown_content = \"\"\n",
    "    \n",
    "    for i, scene in enumerate(scenes, 1):\n",
    "        start = scene['start_time']\n",
    "        end = scene['end_time']\n",
    "        scene_transcription = merge_chunks_by_timerange(transcription['chunks'], start, end)\n",
    "        \n",
    "        # Save frame image\n",
    "        frame = get_frame_at_timestamp(video_file, max(end - 3, (start + end) // 2))\n",
    "        image_filename = f\"{video_name}_scene_{i}.jpg\"\n",
    "        frame.save(output_path / image_filename)\n",
    "        \n",
    "        # Add scene to markdown - only transcription and image\n",
    "        markdown_content += f\"{scene_transcription}\\n\\n\"\n",
    "        markdown_content += f\"![Scene {i}]({image_filename})\\n\\n\"\n",
    "    \n",
    "    # Write markdown file\n",
    "    markdown_path = output_path / f\"readme.md\"\n",
    "    with open(markdown_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_content)\n",
    "    \n",
    "    return markdown_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f57b34e-db7c-480a-8d95-10ff96037118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_mp4_files(folder_path: str) -> list[str]:\n",
    "    import os\n",
    "    import re\n",
    "    \n",
    "    def get_scene_number(filename: str) -> int:\n",
    "        match = re.search(r'Scene-(\\d+)', filename)\n",
    "        return int(match.group(1)) if match else float('inf')\n",
    "    \n",
    "    mp4_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.lower().endswith('.mp4'):\n",
    "            mp4_files.append(os.path.join(folder_path, file))\n",
    "    \n",
    "    return sorted(mp4_files, key=get_scene_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f44d247-57cf-4a17-a304-cdd56dc6ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips = list_mp4_files('./video_clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4dc5de-2f3a-4973-85ef-94a7c55805d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4237d0-9ab2-4c12-8e79-6d4b42685ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-001.mp4\n",
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-002.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-003.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-004.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-005.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-006.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-007.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-008.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-009.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-010.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "\n",
      "Attempt 1 failed.\n",
      "Error: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic string:\n",
      "The video can be split into the following scenes:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"scenes\": [\n",
      "        {\n",
      "            \"start_time\": \"00:00\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Opening Visualization\",\n",
      "            \"description\": \"The video begins with a visual representation of various neural network operations using green squares to illustrate interconnectedness. The central text states: 'but not all threads want to work independently.' This is followed by an explanation that threads are rarely completely independent, emphasizing the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The visual representation is reiterated with consistent green squares and the same text, reinforcing the earlier point about thread interdependence.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reinforcement of the concept about thread interdependence continues with the same visual and textual elements, solidifying the idea in the viewer's mind.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reiteration of the visual representation and the text continues, maintaining focus on the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The consistent reinforcement of the visual elements and text persists, ensuring the viewer comprehends the idea of interdependent neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The visual and textual elements are reiterated once again, emphasizing the importance of interdependence among neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The continuation of reinforcing the visual and textual elements remains consistent, highlighting the interdependence of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"Once again, the visual and textual elements are presented, emphasizing the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reinforcement of the visual and textual elements persists, ensuring a focus on the idea of interdependent neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reiteration of visual and textual elements continues, underscoring the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The consistent reiteration of visual and textual elements remains, emphasizing the interdependence of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reinforcement of visual and textual elements persists, highlighting the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reiteration of visual and textual elements continues, emphasizing the importance of interdependence among neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The consistent reiteration of visual and textual elements remains, underscoring the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reinforcement of visual and textual elements persists, highlighting the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reiteration of visual and textual elements continues, emphasizing the importance of interdependence among neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The consistent reiteration of visual and textual elements remains, underscoring the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reiteration of visual and textual elements persists, highlighting the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reinforcement of visual and textual elements continues, emphasizing the importance of interdependence among neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The consistent reiteration of visual and textual elements remains, underscoring the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reiteration of visual and textual elements persists, highlighting the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reinforcement of visual and textual elements continues, emphasizing the importance of interdependence among neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The consistent reiteration of visual and textual elements remains, underscoring the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reiteration of visual and textual elements persists, highlighting the collaborative nature of neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The reinforcement of visual and textual elements continues, emphasizing the importance of interdependence among neural network threads.\"\n",
      "        },\n",
      "        {\n",
      "            \"start_time\": \"00:40\",\n",
      "            \"end_time\": \"00:40\",\n",
      "            \"title\": \"Reiteration of Visualization\",\n",
      "            \"description\": \"The consistent reiteration of visual and textual elements remains, underscoring the collaborative nature of neural network threads.\"\n",
      "        \n",
      "\n",
      "using flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-011.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-012.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-013.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "Processing video clip: ./video_clips/How GPU Computing Works ｜ GTC 2021 [3l10o0DYJXg]-Scene-014.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aria/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for i, video_clip in enumerate(video_clips):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'Processing video clip: {video_clip}')\n",
    "    process_video_to_doc(video_clip, f\"clip_{i}\", './hqq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1572d8-974a-4d4b-98c7-9cbd83f70605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
